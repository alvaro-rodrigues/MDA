question,answer,subject
Different communities have different visions of data mining. Can you give the epistemological perspective on data mining; the one from the database community; the machine learning community; the inductive database vision; the way businesses consider data mining?,The epistemological perspective is based on empirism; which claims that humans aquire knowledge from experiments and look into data. Databae perspective belives that patterns are the results of complex queries an analyst makes. For ML patterns are an abstraction of the data; they are information analgorithm can learn from. A inductive query is based in two main arguments; onde from the database which is the dataset; and another from a pattern space; a especific pattern. Patterns allow a better understanding of a the “activity” of acompany; hence betterdecisionstaken by the manager.,perspective
Give an abstract vision of the knowledge discovery process and qualify it.,The pattern discovery process is iterative; hence statistics and visualization techniques; on both the data and the patterns; are essential. It involves pre-processing steps to get a dataset that is relevant to the analysis and can be processed by chosen data mining algorithms.,knowledge discovery
When mining data; the analyst should always be careful of the many problems encountered in real datasets. Can you give some of them? What statistical assumptions are usually made on the objects in the dataset? Which one sampling bias violates? What is Berkson's paradox? Give an example.,Missing data and irrelevant information. A common assumption is to presume that a sample represents exactly the real behavior of the data. Selection from a specific area. Is a result in conditional probability and statistics which is often found to be counterintuitive; and hence a veridical paradox. Suppose you will only date a girl if his niceness plus hers handsomeness exceeds some threshold. The rude girl that you date must have been even more handsome to qualify.,problems|perspective
"Many datasets describe objects with attributes. Categorize those attributes w.r.t. their ""types"" and explain what kind of processes (derivation of other attributes; statistics; and data mining algorithms) requires what ""type"" of attribute(s).",Nominal: values that can be compared in equality. Ordinal: values that represents a ordering in some spectrum. Interval-sclaed: values that can divide other values in a part of a spectrum. Ratio-scaled: value that represents grades in a scale; usually; percentages.,attributes
What does it mean for a statistic to be robust? Can you give examples of a robust and a non-robust statistic of the centrality of a distribution? Of its dispersion? Of the correlation between two interval-scaled attributes?,A robust statistic is insensitive to extreme values. Median and mean. Median absolute deviation and standart deviation. Diference between the median of the attributes distances and the distance of two attributes and the distance of two attributes.,robust statistic
What is an outlier? What visualization helps in discovering outliers w.r.t. one attribute?; two attributes? Do you know a way to detect outliers in a higher-dimensional space?,Outlier is a data point that differs significantly from other observations. Normal probability plots and box plots. Subspace and correlation based techniques,outlier
